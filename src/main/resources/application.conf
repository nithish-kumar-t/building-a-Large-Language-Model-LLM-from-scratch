local {
  fs.defaultFS = "hdfs://localhost:9000"
  mapreduce.job.reduces = 1
  mapreduce.input.fileinputformat.split.maxsize = 67108864 // 64 MB
  inputPath = "/input/input.txt"
  outputPath = "/output/"
  epochs = 10
}

test {
  fs.defaultFS = "local"
  mapreduce.job.reduces = 1
  mapreduce.input.fileinputformat.split.maxsize = 67108864 // 64 MB
  epochs = 10
  inputPath = "/Users/tnithish/Learning/cs-401/building-a-Large-Language-Model-LLM-from-scratch/src/main/resources/input.txt"
  outputPath = "/Users/tnithish/Learning/cs-401/building-a-Large-Language-Model-LLM-from-scratch/src/main/resources/output/"
}

cloud {
  fs.defaultFS = "hdfs://localhost:9000"
  mapreduce.job.reduces = 1
  mapreduce.input.fileinputformat.split.maxsize = 134217728 // 128 MB
  epochs = 10
  inputPath  = "s3://hw1-training-llm/input/"
  outputPath = "s3://hw1-training-llm/output/"
}


//  mapred.input.format.class = "org.apache.hadoop.mapred.TextInputFormat"
//  mapred.output.format.class = "org.apache.hadoop.mapred.TextOutputFormat"